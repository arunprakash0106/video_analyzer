import cv2
import tkinter as tk
from tkinter import filedialog
from PIL import Image, ImageTk
from ultralytics import YOLO
import numpy as np
import time

# Load YOLOv8 model
model = YOLO('yolov8n.pt')  # Using YOLOv8 nano for speed

# Classes of interest (IDs based on COCO dataset)
TARGET_CLASSES = {
    63: 'laptop',  # Laptop class ID
    64: 'mouse'    # Mouse class ID
}

# Object Tracker Class
class ObjectTracker:
    def __init__(self):
        self.next_id = 1
        self.objects = {}  # Format: {id: (center_x, center_y, last_seen, class_id)}
        self.timers = {}   # Format: {id: start_time}
        self.max_disappeared = 30  # Frames to wait before considering object lost

    def update(self, detections, frame_count):
        current_time = time.time()
        matched_ids = set()

        for (x1, y1, x2, y2, class_id, confidence) in detections:
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            min_dist = float('inf')
            matched_id = None

            for obj_id, (prev_x, prev_y, last_seen, obj_class_id) in self.objects.items():
                if class_id == obj_class_id:
                    dist = np.linalg.norm([center_x - prev_x, center_y - prev_y])
                    if dist < min_dist and dist < 75:
                        min_dist = dist
                        matched_id = obj_id

            if matched_id is None:
                matched_id = self.next_id
                self.next_id += 1
                self.timers[matched_id] = current_time

            self.objects[matched_id] = (center_x, center_y, frame_count, class_id)
            matched_ids.add(matched_id)

        # Keep unmatched objects if not disappeared for too long
        self.objects = {obj_id: (x, y, last_seen, cls_id) for obj_id, (x, y, last_seen, cls_id) in self.objects.items()
                        if frame_count - last_seen <= self.max_disappeared or obj_id in matched_ids}

        return self.objects

    def get_presence_time(self, obj_id):
        return time.time() - self.timers.get(obj_id, time.time())

# GUI Application
class VideoAnalyzerApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Video Object Detector")

        self.upload_btn = tk.Button(root, text="Upload Video", command=self.upload_video)
        self.upload_btn.pack(pady=10)

        self.video_label = tk.Label(root)
        self.video_label.pack()

        self.tracker = ObjectTracker()

    def upload_video(self):
        file_path = filedialog.askopenfilename(filetypes=[("Video files", "*.mp4;*.avi;*.mov")])
        if file_path:
            self.analyze_video(file_path)

    def analyze_video(self, video_path):
        cap = cv2.VideoCapture(video_path)

        frame_count = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1
            if frame_count % 10 == 0:
                results = model(frame)

                detections = []
                for obj in results[0].boxes.data:
                    class_id = int(obj[5])
                    if class_id in TARGET_CLASSES:
                        x1, y1, x2, y2 = map(int, obj[:4])
                        confidence = float(obj[4])
                        detections.append((x1, y1, x2, y2, class_id, confidence))

                tracked_objects = self.tracker.update(detections, frame_count)
                frame = self.draw_detections(frame, tracked_objects, frame_count)

                frame = cv2.resize(frame, (640, 360))
                img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                imgtk = ImageTk.PhotoImage(image=img)
                self.video_label.imgtk = imgtk
                self.video_label.configure(image=imgtk)
                self.root.update()

        cap.release()

    def draw_detections(self, frame, tracked_objects, frame_count):
        for obj_id, (center_x, center_y, last_seen, class_id) in tracked_objects.items():
            color = (0, 255, 0) if class_id == 63 else (255, 0, 0)
            presence_time = self.tracker.get_presence_time(obj_id)
            label = f"{TARGET_CLASSES[class_id]} ID:{obj_id} {presence_time:.1f}s"

            cv2.rectangle(frame, (center_x - 50, center_y - 50), (center_x + 50, center_y + 50), color, 2)

            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(frame, (center_x - 50, center_y - 70), (center_x - 50 + w, center_y - 50), color, -1)
            cv2.putText(frame, label, (center_x - 50, center_y - 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        return frame

# Run the app
if __name__ == "__main__":
    root = tk.Tk()
    app = VideoAnalyzerApp(root)
    root.mainloop()
